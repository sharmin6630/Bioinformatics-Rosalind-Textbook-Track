{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFUu2ssygo_G"
      },
      "source": [
        "# **Task 1**\r\n",
        "\r\n",
        "http://rosalind.info/problems/ba9a/\r\n",
        "\r\n",
        "Construct a Trie from a Collection of Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG_qkgPcgcSZ",
        "outputId": "7d973d28-13a4-407e-ae54-63c681484300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0->1:A\n",
            "1->2:T\n",
            "2->3:A\n",
            "3->4:G\n",
            "4->5:A\n",
            "2->6:C\n",
            "0->7:G\n",
            "7->8:A\n",
            "8->9:T\n"
          ]
        }
      ],
      "source": [
        "class Trie:\r\n",
        "    def __init__(self):\r\n",
        "        self.all_nodes = []\r\n",
        "        self.all_edges = []\r\n",
        "        self.root = self.add_node()\r\n",
        "\r\n",
        "    class node:\r\n",
        "        def __init__(self):\r\n",
        "            self.label = None\r\n",
        "            self.edges = []\r\n",
        "            self.indicator = None\r\n",
        "\r\n",
        "    class edge:\r\n",
        "        def __init__(self):\r\n",
        "            self.from_node = None\r\n",
        "            self.target_node = None\r\n",
        "            self.label = None\r\n",
        "            self.position = None\r\n",
        "    \r\n",
        "    def add_node(self):\r\n",
        "        newNode = Trie.node()\r\n",
        "        newNode.label = len(self.all_nodes)\r\n",
        "        self.all_nodes.append(newNode)\r\n",
        "        return newNode\r\n",
        "\r\n",
        "    def add_edge(self, from_node, target_node, lbl, pos = None):\r\n",
        "        newEdge = Trie.edge()\r\n",
        "        newEdge.from_node = from_node\r\n",
        "        newEdge.target_node = target_node\r\n",
        "        newEdge.label = lbl\r\n",
        "        newEdge.position = pos\r\n",
        "        from_node.edges.append(newEdge)\r\n",
        "        self.all_edges.append(newEdge)\r\n",
        "        return newEdge\r\n",
        "\r\n",
        "def trie_construction(pattern_list):\r\n",
        "    trie = Trie()\r\n",
        "    for pattern in pattern_list:\r\n",
        "        current = trie.root\r\n",
        "        for x in pattern:\r\n",
        "            for edge in current.edges:\r\n",
        "                if edge.label == x:\r\n",
        "                    current = edge.target_node\r\n",
        "                    break\r\n",
        "            else:\r\n",
        "                new_node = trie.add_node()\r\n",
        "                trie.add_edge(current, new_node, x)\r\n",
        "                current = new_node\r\n",
        "    return trie\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    pattern_list = ['ATAGA','ATC', 'GAT']\r\n",
        "    # with open(\"rosalind_ba9a.txt\", \"r+\") as f:\r\n",
        "    #     pattern_list = []\r\n",
        "    #     for line in f.readlines():\r\n",
        "    #         #print(line)\r\n",
        "    #         pattern_list.append(line.strip())\r\n",
        "    trie = trie_construction(pattern_list)\r\n",
        "    for edge in trie.all_edges:\r\n",
        "        print(str(edge.from_node.label) + '->' + str(edge.target_node.label) + ':' + str(edge.label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2raUgBhzlNvl"
      },
      "source": [
        "# **Task 2**\r\n",
        "\r\n",
        "http://rosalind.info/problems/ba9b/\r\n",
        "\r\n",
        "Implement TrieMatching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hn9zQRNlN_u",
        "outputId": "d1d39554-f51b-49ad-ca79-3bad12519e36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 4 11 15\n"
          ]
        }
      ],
      "source": [
        "class Trie:\r\n",
        "    def __init__(self):\r\n",
        "        self.all_nodes = []\r\n",
        "        self.all_edges = []\r\n",
        "        self.root = self.add_node()\r\n",
        "\r\n",
        "    class node:\r\n",
        "        def __init__(self):\r\n",
        "            self.label = None\r\n",
        "            self.edges = []\r\n",
        "            self.indicator = None\r\n",
        "\r\n",
        "    class edge:\r\n",
        "        def __init__(self):\r\n",
        "            self.from_node = None\r\n",
        "            self.target_node = None\r\n",
        "            self.label = None\r\n",
        "            self.position = None\r\n",
        "    \r\n",
        "    def add_node(self):\r\n",
        "        newNode = Trie.node()\r\n",
        "        newNode.label = len(self.all_nodes)\r\n",
        "        self.all_nodes.append(newNode)\r\n",
        "        return newNode\r\n",
        "\r\n",
        "    def add_edge(self, from_node, target_node, lbl, pos = None):\r\n",
        "        newEdge = Trie.edge()\r\n",
        "        newEdge.from_node = from_node\r\n",
        "        newEdge.target_node = target_node\r\n",
        "        newEdge.label = lbl\r\n",
        "        newEdge.position = pos\r\n",
        "        from_node.edges.append(newEdge)\r\n",
        "        self.all_edges.append(newEdge)\r\n",
        "        return newEdge\r\n",
        "\r\n",
        "def trie_construction(pattern_list):\r\n",
        "    trie = Trie()\r\n",
        "    for pattern in pattern_list:\r\n",
        "        current = trie.root\r\n",
        "        for x in pattern:\r\n",
        "            for edge in current.edges:\r\n",
        "                if edge.label == x:\r\n",
        "                    current = edge.target_node\r\n",
        "                    break\r\n",
        "            else:\r\n",
        "                new_node = trie.add_node()\r\n",
        "                trie.add_edge(current, new_node, x)\r\n",
        "                current = new_node\r\n",
        "    return trie\r\n",
        "\r\n",
        "def prefix_trie_matching(prefix, trie):\r\n",
        "    symbol = prefix[0]\r\n",
        "    node = trie.root\r\n",
        "    idx = 1\r\n",
        "    while True:\r\n",
        "        if len(node.edges) == 0:\r\n",
        "            return True\r\n",
        "        found = False\r\n",
        "        for edge in node.edges:\r\n",
        "            if edge.label == symbol:\r\n",
        "                found = True\r\n",
        "                node = edge.target_node\r\n",
        "                if idx < len(prefix):\r\n",
        "                    symbol = prefix[idx]\r\n",
        "                    idx += 1\r\n",
        "                break\r\n",
        "\r\n",
        "        if not found:\r\n",
        "            return -1\r\n",
        "\r\n",
        "def trie_matching(text, trie):\r\n",
        "    result = []\r\n",
        "    for i in range(len(text)):\r\n",
        "        match = prefix_trie_matching(text[i:], trie)\r\n",
        "        if match != -1:\r\n",
        "            result.append(i)\r\n",
        "    return result\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    text = 'AATCGGGTTCAATCGGGGT'\r\n",
        "    pattern_list = ['ATCG', 'GGGT']\r\n",
        "    # with open(\"rosalind_ba9b.txt\", \"r\") as f:\r\n",
        "    #     lines = f.read().splitlines()\r\n",
        "    #     text = lines[0]\r\n",
        "    #     pattern_list = []\r\n",
        "    #     for i in range(1, len(lines)):\r\n",
        "    #         #print(line)\r\n",
        "    #         pattern_list.append(lines[i])\r\n",
        "    trie = trie_construction(pattern_list)\r\n",
        "    result = trie_matching(text, trie)\r\n",
        "    print(' '.join(str(x) for x in result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Task 5**\r\n",
        "\r\n",
        "http://rosalind.info/problems/ba9g/\r\n",
        "\r\n",
        "Construct the Suffix Array of a String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15, 14, 0, 1, 12, 6, 4, 2, 8, 13, 3, 7, 9, 10, 11, 5\n"
          ]
        }
      ],
      "source": [
        "import operator\r\n",
        "\r\n",
        "def suffix_array(string):\r\n",
        "    suffix_arr = dict()\r\n",
        "    for i in range(len(string)):\r\n",
        "        temp = string[i:]\r\n",
        "        #print(temp)\r\n",
        "        suffix_arr[temp] = i\r\n",
        "    suffix_arr = dict(sorted(suffix_arr.items(), key=operator.itemgetter(0)))\r\n",
        "    return suffix_arr.values()\r\n",
        "\r\n",
        "    \r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    string = \"AACGATAGCGGTAGA$\"\r\n",
        "    # with open(\"rosalind_ba9g.txt\", \"r\") as f:\r\n",
        "    #     string = f.readline().strip()\r\n",
        "    result = suffix_array(string)\r\n",
        "    print(', '.join(str(value) for value in result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lab task: 4\r\n",
        "\r\n",
        "http://rosalind.info/problems/ba9h/\r\n",
        "\r\n",
        "Pattern Matching with the Suffix Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 4 11 15 "
          ]
        }
      ],
      "source": [
        "import operator\r\n",
        "def suffix_array(string):\r\n",
        "    suffix_arr = dict()\r\n",
        "    for i in range(len(string)):\r\n",
        "        temp = string[i:]\r\n",
        "        #print(temp)\r\n",
        "        suffix_arr[temp] = i\r\n",
        "    suffix_arr = dict(sorted(suffix_arr.items(), key=operator.itemgetter(0)))\r\n",
        "    return list(suffix_arr.values())\r\n",
        "\r\n",
        "def pattern_match(text, suffix_arr, pattern_list):\r\n",
        "    result = []\r\n",
        "    for pattern in pattern_list:\r\n",
        "        for i in suffix_arr:\r\n",
        "            if (text[i:i + len(pattern)] == pattern):\r\n",
        "                result.append(i)\r\n",
        "                continue\r\n",
        "            if (len(text[i:]) > len(pattern) and text[i:] > pattern):\r\n",
        "                break\r\n",
        "    result.sort()\r\n",
        "    return result\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    text = 'AATCGGGTTCAATCGGGGT'\r\n",
        "    pattern_list = ['ATCG', 'GGGT']\r\n",
        "    # with open(\"rosalind_ba9h.txt\", \"r\") as f:\r\n",
        "    #     lines = f.read().splitlines()\r\n",
        "    #     text = lines[0]\r\n",
        "    #     pattern_list = []\r\n",
        "    #     for i in range(1, len(lines)):\r\n",
        "    #         #print(line)\r\n",
        "    #         pattern_list.append(lines[i])\r\n",
        "    suffix_arr = suffix_array(text)\r\n",
        "    result = pattern_match(text, suffix_arr, pattern_list)\r\n",
        "    for x in result:\r\n",
        "        print(x, end=\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lab task: 5\r\n",
        "\r\n",
        "http://rosalind.info/problems/ba9i/\r\n",
        "\r\n",
        "Construct the Burrows-Wheeler Transform of a String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ACTGGCT$TGCGGC\n"
          ]
        }
      ],
      "source": [
        "def burrows_wheeler_transform(text):\r\n",
        "    patterns = []\r\n",
        "    for i in range(len(text)):\r\n",
        "        patterns.append(text[i:]+text[:i])\r\n",
        "    patterns = sorted(patterns)\r\n",
        "    ##print(patterns)\r\n",
        "    bwt = ''.join([str[-1] for str in patterns])\r\n",
        "    #print(bwt)\r\n",
        "    return bwt\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    text = 'GCGTGCCTGGTCA$'\r\n",
        "    # with open(\"rosalind_ba9i.txt\", \"r\") as f:\r\n",
        "    #     text = f.read().strip()\r\n",
        "    print(burrows_wheeler_transform(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lab task: 6\r\n",
        "\r\n",
        "http://rosalind.info/problems/ba9j/\r\n",
        "\r\n",
        "Reconstruct a String from its Burrows-Wheeler Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TACATCACGT$\n"
          ]
        }
      ],
      "source": [
        "def bwt_to_text(string):\r\n",
        "    rotation_table = [''] * len(string)\r\n",
        "\r\n",
        "    for j in range(len(string)):\r\n",
        "        for i in range(len(string)):\r\n",
        "            rotation_table[i] = string[i] + rotation_table[i]\r\n",
        "        rotation_table = sorted(rotation_table)\r\n",
        "\r\n",
        "    result = ''\r\n",
        "    for s in rotation_table:\r\n",
        "        if s[-1] == \"$\":\r\n",
        "            result = s\r\n",
        "            break\r\n",
        "    return result\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    bwt = 'TTCCTAACG$A'\r\n",
        "    # with open(\"rosalind_ba9j.txt\", \"r\") as f:\r\n",
        "    #     bwt = f.read().strip()\r\n",
        "    print(bwt_to_text(bwt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lab task: 7\r\n",
        "\r\n",
        "http://rosalind.info/problems/ba9k/\r\n",
        "\r\n",
        "Generate the Last-to-First Mapping of a String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "def occurences_positions(bwt, ch):\r\n",
        "    return [i for i, letter in enumerate(bwt) if letter == ch]\r\n",
        "\r\n",
        "def last_to_first(bwt, i):\r\n",
        "    ch = bwt[i]\r\n",
        "    occurence = occurences_positions(bwt, ch)\r\n",
        "    order = occurence.index(i)\r\n",
        "    #print(order, sorted(bwt), sorted(bwt).index(ch))\r\n",
        "    return sorted(bwt).index(ch) + order\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    bwt = 'T$GACCA'\r\n",
        "    i = 3\r\n",
        "    # with open(\"rosalind_ba9k.txt\", \"r\") as f:\r\n",
        "    #     bwt = f.readline().strip()\r\n",
        "    #     i = int(f.readline())\r\n",
        "    print(last_to_first(bwt, i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lab task: 8\r\n",
        "\r\n",
        "http://rosalind.info/problems/ba9n/\r\n",
        "\r\n",
        "Find All Occurrences of a Collection of Patterns in a String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 4 11 15\n"
          ]
        }
      ],
      "source": [
        "import operator\r\n",
        "\r\n",
        "def burrows_wheeler_transform(text):\r\n",
        "    patterns = []\r\n",
        "    for i in range(len(text)):\r\n",
        "        patterns.append(text[i:]+text[:i])\r\n",
        "    patterns = sorted(patterns)\r\n",
        "    ##print(patterns)\r\n",
        "    bwt = ''.join([str[-1] for str in patterns])\r\n",
        "    #print(bwt)\r\n",
        "    return bwt\r\n",
        "\r\n",
        "def find_first_occurance(BWT):\r\n",
        "    first_occurrences = dict()\r\n",
        "    for idx, symbol in enumerate(sorted(BWT)):\r\n",
        "        if symbol not in first_occurrences.keys():\r\n",
        "            first_occurrences[symbol] = idx\r\n",
        "    return first_occurrences\r\n",
        "\r\n",
        "def create_check_point_array(BWT, C):\r\n",
        "    symbol_list = list(set(BWT))\r\n",
        "    check_point_array = dict()\r\n",
        "    for idx in range(0, len(BWT), C):\r\n",
        "        check_point_array[idx] = {}\r\n",
        "        for symbol in symbol_list:\r\n",
        "            check_point_array[idx][symbol] = BWT[:idx].count(symbol)\r\n",
        "    return check_point_array\r\n",
        "\r\n",
        "def create_suffix_array(string):\r\n",
        "    suffix_arr = dict()\r\n",
        "    for i in range(len(string)):\r\n",
        "        temp = string[i:]\r\n",
        "        #print(temp)\r\n",
        "        suffix_arr[temp] = i\r\n",
        "    suffix_arr = dict(sorted(suffix_arr.items(), key=operator.itemgetter(0)))\r\n",
        "    return list(suffix_arr.values())\r\n",
        "\r\n",
        "def create_partial_suffix_array(text, k):\r\n",
        "    suffixes = []\r\n",
        "    suffix_array = create_suffix_array(text)\r\n",
        "    partial_suffix_array = {i: x for i, x in enumerate(suffix_array) if x % k == 0}\r\n",
        "    #print(partial_suffix_array)\r\n",
        "    return partial_suffix_array\r\n",
        "\r\n",
        "def count_symbol(check_point_array, idx, last_column, symbol):\r\n",
        "    values = [x for x in check_point_array.keys() if x <= idx]\r\n",
        "    nearest_idx = min(values, key=lambda x: abs(x - idx))\r\n",
        "    count = check_point_array[nearest_idx][symbol]\r\n",
        "    count += last_column[nearest_idx:idx].count(symbol)\r\n",
        "    return count\r\n",
        "\r\n",
        "def multiple_pattern_matching(first_occurrences, last_column, pattern, check_point_array):\r\n",
        "    top = 0\r\n",
        "    bottom = len(last_column) - 1\r\n",
        "    while top <= bottom:\r\n",
        "        if len(pattern) != 0:\r\n",
        "            symbol = pattern[-1]\r\n",
        "            pattern = pattern[:-1]\r\n",
        "            if symbol in last_column[top: bottom + 1]:\r\n",
        "                #print(last_column[top: bottom + 1])\r\n",
        "                top = first_occurrences[symbol] + count_symbol(check_point_array, \r\n",
        "                                                               top, last_column, symbol)\r\n",
        "                bottom = first_occurrences[symbol] + count_symbol(check_point_array, \r\n",
        "                                                                  bottom + 1, last_column, symbol) - 1\r\n",
        "            else:\r\n",
        "                return False, False\r\n",
        "        else:\r\n",
        "            return top, bottom\r\n",
        "\r\n",
        "def find_all_occurance(text, pattern_list, C):\r\n",
        "    BWT = burrows_wheeler_transform(text + '$')\r\n",
        "    first_occurrences = find_first_occurance(BWT)\r\n",
        "\r\n",
        "    check_point_array = create_check_point_array(BWT, C)\r\n",
        "    partial_suffix_array = create_partial_suffix_array(text+'$', C)\r\n",
        "\r\n",
        "    positions_list = []\r\n",
        "    for pattern in pattern_list:\r\n",
        "        top, bottom = multiple_pattern_matching(first_occurrences, BWT, pattern, \r\n",
        "                                                check_point_array)\r\n",
        "        if top:\r\n",
        "            for idx in range(top, bottom + 1):\r\n",
        "                to_add = 0\r\n",
        "                while idx not in partial_suffix_array.keys():\r\n",
        "                    idx = first_occurrences[BWT[idx]] + count_symbol(check_point_array, \r\n",
        "                                                                     idx, BWT, BWT[idx])\r\n",
        "                    to_add += 1\r\n",
        "                positions_list.append(partial_suffix_array[idx] + to_add)\r\n",
        "    return sorted(positions_list)\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    text = \"AATCGGGTTCAATCGGGGT\"\r\n",
        "    pattern_list = ['ATCG', 'GGGT']\r\n",
        "    # with open(\"rosalind_ba9n.txt\", \"r\") as f:\r\n",
        "    #     f = f.read().splitlines()\r\n",
        "    #     text = f[0]\r\n",
        "    #     for i in range(1, len(f)):\r\n",
        "    #         pattern_list.append(f[i])\r\n",
        "\r\n",
        "    positions_list = find_all_occurance(text, pattern_list, C=100)\r\n",
        "    print(' '.join(str(pos) for pos in positions_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lab task: 9\r\n",
        "\r\n",
        "http://rosalind.info/problems/ba9o/\r\n",
        "\r\n",
        "Find All Approximate Occurrences of a Collection of Patterns in a String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 4 4 6 7 8 9\n"
          ]
        }
      ],
      "source": [
        "import operator\r\n",
        "\r\n",
        "def burrows_wheeler_transform(text):\r\n",
        "    patterns = []\r\n",
        "    for i in range(len(text)):\r\n",
        "        patterns.append(text[i:]+text[:i])\r\n",
        "    patterns = sorted(patterns)\r\n",
        "    ##print(patterns)\r\n",
        "    bwt = ''.join([str[-1] for str in patterns])\r\n",
        "    #print(bwt)\r\n",
        "    return bwt\r\n",
        "\r\n",
        "def find_first_occurance(BWT):\r\n",
        "    first_occurrences = dict()\r\n",
        "    for idx, symbol in enumerate(sorted(BWT)):\r\n",
        "        if symbol not in first_occurrences.keys():\r\n",
        "            first_occurrences[symbol] = idx\r\n",
        "    return first_occurrences\r\n",
        "\r\n",
        "def create_check_point_array(BWT, C):\r\n",
        "    symbol_list = list(set(BWT))\r\n",
        "    check_point_array = dict()\r\n",
        "    for idx in range(0, len(BWT), C):\r\n",
        "        check_point_array[idx] = {}\r\n",
        "        for symbol in symbol_list:\r\n",
        "            check_point_array[idx][symbol] = BWT[:idx].count(symbol)\r\n",
        "    return check_point_array\r\n",
        "\r\n",
        "def create_suffix_array(string):\r\n",
        "    suffix_arr = dict()\r\n",
        "    for i in range(len(string)):\r\n",
        "        temp = string[i:]\r\n",
        "        #print(temp)\r\n",
        "        suffix_arr[temp] = i\r\n",
        "    suffix_arr = dict(sorted(suffix_arr.items(), key=operator.itemgetter(0)))\r\n",
        "    return list(suffix_arr.values())\r\n",
        "\r\n",
        "def create_partial_suffix_array(text, k):\r\n",
        "    suffixes = []\r\n",
        "    suffix_array = create_suffix_array(text)\r\n",
        "    partial_suffix_array = {i: x for i, x in enumerate(suffix_array) if x % k == 0}\r\n",
        "    #print(partial_suffix_array)\r\n",
        "    return partial_suffix_array\r\n",
        "\r\n",
        "def count_symbol(check_point_array, idx, last_column, symbol):\r\n",
        "    values = [x for x in check_point_array.keys() if x <= idx]\r\n",
        "    nearest_idx = min(values, key=lambda x: abs(x - idx))\r\n",
        "    count = check_point_array[nearest_idx][symbol]\r\n",
        "    count += last_column[nearest_idx:idx].count(symbol)\r\n",
        "    return count\r\n",
        "\r\n",
        "def multiple_pattern_matching(first_occurrences, last_column, pattern, check_point_array):\r\n",
        "    top = 0\r\n",
        "    bottom = len(last_column) - 1\r\n",
        "    while top <= bottom:\r\n",
        "        if len(pattern) != 0:\r\n",
        "            symbol = pattern[-1]\r\n",
        "            pattern = pattern[:-1]\r\n",
        "            if symbol in last_column[top: bottom + 1]:\r\n",
        "                #print(last_column[top: bottom + 1])\r\n",
        "                top = first_occurrences[symbol] + count_symbol(check_point_array, \r\n",
        "                                                               top, last_column, symbol)\r\n",
        "                bottom = first_occurrences[symbol] + count_symbol(check_point_array, \r\n",
        "                                                                  bottom + 1, last_column, symbol) - 1\r\n",
        "            else:\r\n",
        "                return False, False\r\n",
        "        else:\r\n",
        "            return top, bottom\r\n",
        "\r\n",
        "def pattern_to_seeds(pattern, d):\r\n",
        "    minsize = len(pattern) // (d + 1)\r\n",
        "    cut_points = list(range(0, len(pattern) - minsize + 1, minsize))\r\n",
        "    cut_points.append(len(pattern))\r\n",
        "    seeds = []\r\n",
        "    offsets = []\r\n",
        "    for i in range(1, len(cut_points)):\r\n",
        "        seeds.append(pattern[cut_points[i - 1]: cut_points[i]])\r\n",
        "        offsets.append(cut_points[i - 1])\r\n",
        "    return seeds, offsets\r\n",
        "\r\n",
        "def find_seed_positions(seed, first_occurrences, BWT, check_point_array, partial_suffix_array):\r\n",
        "    seed_pos_list = []\r\n",
        "    top, bottom = multiple_pattern_matching(first_occurrences, BWT, seed, check_point_array)\r\n",
        "    if top:\r\n",
        "        for idx in range(top, bottom + 1):\r\n",
        "            to_add = 0\r\n",
        "            while idx not in partial_suffix_array.keys():\r\n",
        "                idx = first_occurrences[BWT[idx]] + count_symbol(check_point_array, \r\n",
        "                                                                 idx, BWT, BWT[idx])\r\n",
        "                to_add += 1\r\n",
        "            seed_pos_list.append(partial_suffix_array[idx] + to_add)\r\n",
        "    return seed_pos_list\r\n",
        "\r\n",
        "def find_all_approximate_occurance(text, pattern_list, d, C):\r\n",
        "    BWT = burrows_wheeler_transform(text + '$')\r\n",
        "    first_occurrences = find_first_occurance(BWT)\r\n",
        "\r\n",
        "    check_point_array = create_check_point_array(BWT, C)\r\n",
        "    partial_suffix_array = create_partial_suffix_array(text+'$', C)\r\n",
        "\r\n",
        "    positions_list = []\r\n",
        "    for pattern in pattern_list:\r\n",
        "        seeds_list, offsets_list = pattern_to_seeds(pattern, d)\r\n",
        "        pattern_pos_list = set()\r\n",
        "        for candidate_seed, offset in zip(seeds_list, offsets_list):\r\n",
        "            seed_pos_list = find_seed_positions(candidate_seed, first_occurrences, \r\n",
        "                                                BWT, check_point_array, \r\n",
        "                                                partial_suffix_array)\r\n",
        "            for candidate_pos in seed_pos_list:\r\n",
        "                pattern_position = candidate_pos - offset\r\n",
        "                if pattern_position >= 0 and pattern_position + len(pattern) <= len(text):\r\n",
        "                    approximate_match_flag = True\r\n",
        "                    num_mismatch = 0\r\n",
        "                    for idx, symbol in enumerate(pattern):\r\n",
        "                        if symbol != text[pattern_position + idx]:\r\n",
        "                            num_mismatch += 1\r\n",
        "                            if num_mismatch > d:\r\n",
        "                                approximate_match_flag = False\r\n",
        "                                break\r\n",
        "                    if approximate_match_flag:\r\n",
        "                        pattern_pos_list.add(pattern_position)\r\n",
        "        positions_list += list(pattern_pos_list)\r\n",
        "\r\n",
        "    return sorted(positions_list)\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    text = \"ACATGCTACTTT\"\r\n",
        "    pattern_list = ['ATT', 'GCC', 'GCTA', 'TATT']\r\n",
        "    d = 1\r\n",
        "    # with open(\"rosalind_ba9o.txt\", \"r\") as f:\r\n",
        "    #     f = f.read().splitlines()\r\n",
        "    #     text = f[0]\r\n",
        "    #     pattern_list = [pattern for pattern in f[1].split(' ')]\r\n",
        "    #     d = int(f[2])\r\n",
        "\r\n",
        "    positions_list = find_all_approximate_occurance(text, pattern_list, d, C=100)\r\n",
        "    print(' '.join(str(pos) for pos in positions_list))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab62016331091.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}